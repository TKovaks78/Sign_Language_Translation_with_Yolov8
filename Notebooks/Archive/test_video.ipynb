{"cells":[{"cell_type":"markdown","metadata":{"id":"4PQcxyjzmm6t"},"source":["<font size=7> <center> Benchmark - Yolov8 Nano</font></br>\n"]},{"cell_type":"markdown","metadata":{"id":"05ySUXENo_0X"},"source":["# 1- Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":75333,"status":"ok","timestamp":1677149762848,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"},"user_tz":-60},"id":"zegodvLwjDNe","outputId":"d0a01b65-60c9-453d-93e6-4fc56b5981c9"},"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.43 üöÄ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 26.1/78.2 GB disk)\n"]}],"source":["# This line contains my github token. Please do not share it with anyone\n","!git clone https://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@github.com/TKovaks78//Sign_Language_Translation_with_Yolov8.git\n","# Install requirements\n","!pip install -r requirements.txt\n","# Install Ultralytics\n","!pip install ultralytics\n","# Install clearML\n","!pip install clearml\n","# Check GPU\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"YeTwPY2QqFIy","executionInfo":{"status":"ok","timestamp":1677149763386,"user_tz":-60,"elapsed":557,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"}}},"outputs":[],"source":["# Import libraries\n","from clearml import Task\n","from ultralytics import YOLO\n","import matplotlib.pyplot as plt\n","from matplotlib.image import imread\n","import pandas as pd\n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1677149763387,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"},"user_tz":-60},"id":"lpD49A6boAen","outputId":"10c7729f-8ed1-437e-d94b-56f42ea2bcef"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: CLEARML_WEB_HOST=https://app.clear.ml\n","env: CLEARML_API_HOST=https://api.clear.ml\n","env: CLEARML_FILES_HOST=https://files.clear.ml\n","env: CLEARML_API_ACCESS_KEY=1XQ9HTBHM5TXCMJCF00W\n","env: CLEARML_API_SECRET_KEY=LN6gjflJlyED9HOgyyG3F4G1DMXiRr1FKCi8tXwL7MhSUvMP5e\n"]}],"source":["# Save models on clearML\n","%env CLEARML_WEB_HOST=https://app.clear.ml\n","%env CLEARML_API_HOST=https://api.clear.ml\n","%env CLEARML_FILES_HOST=https://files.clear.ml\n","%env CLEARML_API_ACCESS_KEY=1XQ9HTBHM5TXCMJCF00W\n","%env CLEARML_API_SECRET_KEY=LN6gjflJlyED9HOgyyG3F4G1DMXiRr1FKCi8tXwL7MhSUvMP5e"]},{"cell_type":"markdown","metadata":{"id":"_2l08pb3p-Tq"},"source":["# 2. Train"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"sPbIYiY1rfuO","executionInfo":{"status":"ok","timestamp":1677149763389,"user_tz":-60,"elapsed":14,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"}}},"outputs":[],"source":["# Define main folder path\n","path = \"/content/Sign_Language_Translation_with_Yolov8\"\n","\n","# Define yaml file path \n","yaml_path = os.path.join(path, \"data/\", \"data.yaml\")\n","\n","# Define experience name\n","exp_name = \"benchmark_nano\"\n","\n","project_name = \"DL_-_Sign_Detection\" # DO NOT CHANGE THE PROJECT NAME"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["766e5873d5f94600b4bcb71cfcec6efd","120e844885494438a4b1afb1e5ffe5b5","ae779d603a49440ebcf42dcf009aa5ef","101ec31d0ebd4b8181e36ef55a96a826","735b1752d46e42b8a61fac353e1863a0","7a2e334d1a794a83b8440934f7d725ee","fe3b7a591b2f447fa3ce50730649a0f8","5fbc86026adb4af5a3752a6eeb2f085c","4e405c0be9354a299cde826f09593957","26837f892a524cc3b0643cd24e04c612","15add07839204a8fa90e6904fdff1c70"]},"executionInfo":{"elapsed":719,"status":"ok","timestamp":1677149764095,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"},"user_tz":-60},"id":"lE-BJQx41yw5","outputId":"1eac9df5-68b1-4a62-c937-453a392ba99f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/6.23M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"766e5873d5f94600b4bcb71cfcec6efd"}},"metadata":{}}],"source":["# Load a model\n","yolo_model = YOLO(\"yolov8n.pt\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12653,"status":"ok","timestamp":1677149776734,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"},"user_tz":-60},"id":"jx5uO2UHsGlK","outputId":"9bcfbc18-aeb5-4922-8c1a-411cda353a92"},"outputs":[{"output_type":"stream","name":"stdout","text":["ClearML Task: created new task id=77028948fa4c461fade26ebc1279a8e4\n","2023-02-23 10:56:10,353 - clearml.Task - INFO - Storing jupyter notebook directly as code\n","ClearML results page: https://app.clear.ml/projects/c6ca2057e9f140d38f5fc76e83cf8781/experiments/77028948fa4c461fade26ebc1279a8e4/output/log\n"]}],"source":["task = Task.init(project_name = project_name, # DO NOT CHANGE PROJECT NAME\n","                 task_name=exp_name) # Name your experience"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f56087b4173f490995dbfc3e19daa9da","71e5bbbd56ca4ea2ab75923baba23d1b","620d9275539440d68c50e8e399e8b000","81c9cd9c06bd4227bac33ab1ff7e7e28","c37569cbcc3f4a3ea9a71cd1acc67816","d19df18605ea4612b62f63e3363ddb3d","f31ca0841ade4b60a5b0f081decf6c22","4171f0c132a44e44a2f8528d29887099","8f7b1d924d8444babb5a1dd96f5dd6d1","e8287ccfe3d54ff7a5dc2ef9bfa70f9b","19aff64873ca4469a8c3bd734ef10e0b"]},"id":"R65pO6Ycl68S","outputId":"b396e396-5832-42e7-da27-092b6d61a579","executionInfo":{"status":"ok","timestamp":1677150639572,"user_tz":-60,"elapsed":862852,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.43 üöÄ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/Sign_Language_Translation_with_Yolov8/data/data.yaml, epochs=20, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=DL_-_Sign_Detection, name=benchmark_nano, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=DL_-_Sign_Detection/benchmark_nano\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/755k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f56087b4173f490995dbfc3e19daa9da"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Overriding model.yaml nc=80 with nc=26\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    756382  ultralytics.nn.modules.Detect                [26, [64, 128, 256]]          \n","Model summary: 225 layers, 3015918 parameters, 3015902 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Sign_Language_Translation_with_Yolov8/data/train/labels... 508 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 508/508 [00:00<00:00, 1161.96it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Sign_Language_Translation_with_Yolov8/data/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Sign_Language_Translation_with_Yolov8/data/valid/labels... 104 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 104/104 [00:00<00:00, 1092.73it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Sign_Language_Translation_with_Yolov8/data/valid/labels.cache\n","Plotting labels to DL_-_Sign_Detection/benchmark_nano/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mDL_-_Sign_Detection/benchmark_nano\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/20      2.52G      1.031      4.526      1.454         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.23it/s]\n","                   all        104        104          0          0          0          0\n"]},{"output_type":"stream","name":"stdout","text":["2023-02-23 10:57:18,341 - clearml.frameworks - INFO - Found existing registered model id=b0c4a01e391d4cff949cc57c82b9daba [/content/DL_-_Sign_Detection/benchmark_nano/weights/last.pt] reusing it.\n","2023-02-23 10:57:29,136 - clearml.frameworks - INFO - Found existing registered model id=a7e5a9615adf4ba2917b6f745f961085 [/content/DL_-_Sign_Detection/benchmark_nano/weights/best.pt] reusing it.\n"]},{"output_type":"stream","name":"stderr","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/20      2.94G     0.7974      4.145      1.281         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:20<00:00,  1.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.40it/s]\n","                   all        104        104     0.0417      0.538      0.128      0.106\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/20      2.94G     0.8924      3.885      1.329         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:18<00:00,  1.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.40it/s]\n","                   all        104        104      0.801     0.0989      0.165      0.106\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/20      2.94G     0.9738        3.6      1.407         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:18<00:00,  1.73it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.89it/s]\n","                   all        104        104      0.191      0.415      0.228      0.192\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/20      2.94G     0.9859      3.438      1.382         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:20<00:00,  1.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.24it/s]\n","                   all        104        104      0.219      0.383      0.251      0.186\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/20      2.94G     0.9988      3.266      1.363         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:18<00:00,  1.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.26it/s]\n","                   all        104        104      0.436      0.487      0.363      0.253\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/20      2.94G     0.9466      3.171      1.353         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:18<00:00,  1.77it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.15it/s]\n","                   all        104        104      0.296      0.453      0.378      0.305\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/20      2.94G     0.9595      2.952      1.335         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:19<00:00,  1.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.38it/s]\n","                   all        104        104      0.291       0.54      0.388      0.236\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/20      2.94G      0.912      2.825      1.291         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:18<00:00,  1.78it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.33it/s]\n","                   all        104        104       0.42      0.612       0.52      0.397\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/20      2.94G     0.8807      2.706      1.279         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:18<00:00,  1.77it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.75it/s]\n","                   all        104        104      0.379      0.642      0.553      0.452\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/20      2.94G     0.6769       2.89      1.229         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:12<00:00,  2.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.37it/s]\n","                   all        104        104      0.503      0.626      0.615      0.464\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/20      2.94G     0.6483      2.647      1.189         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:11<00:00,  2.85it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.32it/s]\n","                   all        104        104      0.539      0.649      0.664      0.559\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/20      2.94G     0.6304      2.516      1.171         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:10<00:00,  2.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.94it/s]\n","                   all        104        104      0.644      0.683      0.785      0.661\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/20      2.94G     0.5842      2.313       1.13         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:11<00:00,  2.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.25it/s]\n","                   all        104        104      0.668      0.706        0.8        0.7\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/20      2.94G     0.5927      2.266       1.13         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:11<00:00,  2.76it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.33it/s]\n","                   all        104        104      0.683      0.761      0.821      0.717\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/20      2.94G     0.5588      2.059      1.086         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:11<00:00,  2.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.36it/s]\n","                   all        104        104      0.715      0.683      0.785      0.696\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/20      2.94G       0.54      1.968       1.09         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:09<00:00,  3.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.62it/s]\n","                   all        104        104      0.802      0.747      0.861       0.76\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/20      2.94G     0.5286      1.888      1.086         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:11<00:00,  2.78it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.37it/s]\n","                   all        104        104      0.773      0.817      0.879       0.78\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/20      2.94G     0.5178      1.803      1.068         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:11<00:00,  2.82it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.36it/s]\n","                   all        104        104      0.721       0.88      0.902      0.808\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/20      2.94G     0.4849      1.698       1.03         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:11<00:00,  2.75it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.16it/s]\n","                   all        104        104      0.779      0.876      0.918      0.823\n","\n","20 epochs completed in 0.207 hours.\n","Optimizer stripped from DL_-_Sign_Detection/benchmark_nano/weights/last.pt, 6.2MB\n","Optimizer stripped from DL_-_Sign_Detection/benchmark_nano/weights/best.pt, 6.2MB\n","\n","Validating DL_-_Sign_Detection/benchmark_nano/weights/best.pt...\n","Ultralytics YOLOv8.0.43 üöÄ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","Model summary (fused): 168 layers, 3010718 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.12it/s]\n","                   all        104        104      0.778      0.877      0.918      0.823\n","                     A        104          3          1      0.435       0.83      0.798\n","                     B        104          3      0.738      0.954      0.913      0.831\n","                     C        104          3      0.582          1      0.913       0.83\n","                     D        104          3      0.871      0.667      0.806      0.585\n","                     E        104          4      0.877       0.75      0.912      0.772\n","                     F        104          4      0.957          1      0.995      0.908\n","                     G        104          4      0.879          1      0.995      0.904\n","                     H        104          4      0.879          1      0.995      0.995\n","                     I        104          4      0.665          1      0.995      0.995\n","                     J        104          8      0.829      0.608      0.771      0.556\n","                     K        104          4      0.698       0.75       0.87      0.814\n","                     L        104          4      0.881          1      0.995      0.952\n","                     M        104          4      0.533          1      0.895      0.805\n","                     N        104          4      0.505      0.258      0.711      0.601\n","                     O        104          4      0.589          1      0.945      0.869\n","                     P        104          4      0.789      0.946      0.945      0.726\n","                     Q        104          4        0.8          1      0.995      0.576\n","                     R        104          4      0.994          1      0.995      0.995\n","                     S        104          4      0.868          1      0.995       0.97\n","                     T        104          4       0.54       0.75      0.656      0.587\n","                     U        104          4      0.565          1      0.995       0.97\n","                     V        104          4      0.719          1      0.995       0.97\n","                     W        104          4      0.881          1      0.995      0.946\n","                     X        104          4      0.865          1      0.995      0.909\n","                     Y        104          4          1      0.672      0.856       0.77\n","                     Z        104          4      0.732          1      0.895      0.758\n","Speed: 2.8ms preprocess, 4.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n","Results saved to \u001b[1mDL_-_Sign_Detection/benchmark_nano\u001b[0m\n","Results saved to \u001b[1mDL_-_Sign_Detection/benchmark_nano\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["2023-02-23 11:10:25,659 - clearml.Task - INFO - Completed model upload to https://files.clear.ml/DL_-_Sign_Detection/benchmark_nano.77028948fa4c461fade26ebc1279a8e4/models/best.pt\n","2023-02-23 11:10:35,817 - clearml.Task - INFO - Completed model upload to https://files.clear.ml/DL_-_Sign_Detection/benchmark_nano.77028948fa4c461fade26ebc1279a8e4/models/best.pt\n"]}],"source":["# Train the model\n","yolo_model.train(data= yaml_path,\n","            project=project_name, \n","            epochs=20,   \n","            name=exp_name)"]},{"cell_type":"markdown","metadata":{"id":"j3_QV9WEtnDU"},"source":["<font size =2><u>Note:</u> to change any parameter you just have to add parameter_name=value. The only mandatory parameter is data</br>\n","For example: \n","\n","```\n","# Train the model\n","results_baseline = model.train(data= yaml_path, \n","                              momentum = 0.9\n","                              lrf = 0.0001)\n","```\n","<font size =2>Please refer to the [configuration file](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/yolo/cfg/default.yaml)\n"]},{"cell_type":"markdown","metadata":{"id":"nJj25-eozjBU"},"source":["# 3. Results"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"K_aV20IFFPyw","executionInfo":{"status":"ok","timestamp":1677150644709,"user_tz":-60,"elapsed":5145,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"}}},"outputs":[],"source":["# Loss\n","img = imread(os.path.join(project_name, exp_name, \"results.png\"))\n","plt.figure(figsize=(14,12))\n","plt.imshow(img)\n","plt.show()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"EqTNHBUDzg3V","executionInfo":{"status":"ok","timestamp":1677150652850,"user_tz":-60,"elapsed":8170,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"}}},"outputs":[],"source":["# Confusion matrix\n","img = imread(os.path.join(project_name, exp_name,\"confusion_matrix.png\"))\n","plt.figure(figsize=(14,12))\n","plt.imshow(img)\n","plt.show()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"9bAF0xy5L6N0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677150655383,"user_tz":-60,"elapsed":2544,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"}},"outputId":"010d86e3-9789-4c7b-d66c-9d8783ed06ac"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  epoch    19.00000\n","         train/box_loss     0.48493\n","         train/cls_loss     1.69820\n","         train/dfl_loss     1.02960\n","   metrics/precision(B)     0.77938\n","      metrics/recall(B)     0.87625\n","       metrics/mAP50(B)     0.91756\n","    metrics/mAP50-95(B)     0.82281\n","           val/box_loss     0.51477\n","           val/cls_loss     1.01760\n","           val/dfl_loss     1.07130\n","                 lr/pg0     0.00109\n","                 lr/pg1     0.00109\n","                 lr/pg2     0.00109\n","Name: 19, dtype: float64"]},"metadata":{},"execution_count":10}],"source":["# top mAP50-95 score\n","df = pd.read_csv(os.path.join(project_name, exp_name,\"results.csv\"))\n","max_map50_index = df['    metrics/mAP50-95(B)'].idxmax()\n","result = df.loc[max_map50_index]\n","result"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"3i1ZzRvwyfYG","colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"status":"ok","timestamp":1677150658351,"user_tz":-60,"elapsed":2986,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"}},"outputId":"7c6dd76a-e3d2-4ed9-841f-3b7a7e473f08"},"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/DL_-_Sign_Detection/benchmark_nano/ (stored 0%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/val_batch0_labels.jpg (deflated 9%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/R_curve.png (deflated 6%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/train_batch2.jpg (deflated 3%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/results.png (deflated 7%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/results.csv (deflated 83%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/P_curve.png (deflated 6%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/train_batch321.jpg (deflated 8%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/confusion_matrix.png (deflated 15%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/F1_curve.png (deflated 5%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/PR_curve.png (deflated 18%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/val_batch1_pred.jpg (deflated 10%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/train_batch0.jpg (deflated 3%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/val_batch2_pred.jpg (deflated 12%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/val_batch0_pred.jpg (deflated 9%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/train_batch1.jpg (deflated 3%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/args.yaml (deflated 50%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/val_batch2_labels.jpg (deflated 12%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/train_batch320.jpg (deflated 11%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/events.out.tfevents.1677149785.5b82de039848.632.0 (deflated 71%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/weights/ (stored 0%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/weights/best.pt (deflated 9%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/weights/last.pt (deflated 9%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/val_batch1_labels.jpg (deflated 10%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/train_batch322.jpg (deflated 13%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/labels_correlogram.jpg (deflated 33%)\n","  adding: content/DL_-_Sign_Detection/benchmark_nano/labels.jpg (deflated 29%)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_d3011782-452d-427f-b4de-a217a99c38a7\", \"results.zip\", 18473602)"]},"metadata":{}}],"source":["# Way around to avoid error when saving results\n","import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding\n","\n","# Save results\n","# Write your experience name\n","from google.colab import files\n","!zip -r results.zip /content/DL_-_Sign_Detection/benchmark_nano\n","files.download(\"results.zip\")"]},{"cell_type":"code","source":["!python export.py --weights /content/DL_-_Sign_Detection/benchmark_nano/weights/best.pt --include tflite --img 640"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qsghaQ4j-aCZ","executionInfo":{"status":"ok","timestamp":1677151020496,"user_tz":-60,"elapsed":1993,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"}},"outputId":"730fed83-94e0-4e0f-9077-0b10191fa296"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file 'task=': [Errno 2] No such file or directory\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=export model=yolov8n.pt format=tflite source=/content/DL_-_Sign_Detection/benchmark_nano/weights/best.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g76fZKCE-3DL","executionInfo":{"status":"ok","timestamp":1677151673298,"user_tz":-60,"elapsed":62457,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"}},"outputId":"cef7b67c-15a2-4c45-e4cd-364399d6ad63"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.43 üöÄ Python-3.8.10 torch-1.13.1+cu116 CPU\n","YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov8n.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n","WARNING ‚ö†Ô∏è YOLOv8 TensorFlow export is still under development. Please consider contributing to the effort if you have TF expertise. Thank you!\n","2023-02-23 11:26:54.848689: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-02-23 11:26:54.848843: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-02-23 11:26:54.848863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv8 requirements \"onnx\" \"onnx2tf\" \"sng4onnx\" \"onnxsim\" \"onnx_graphsurgeon\" \"tflite_support\" \"onnxruntime\" not found, attempting AutoUpdate...\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\n","tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n","Collecting onnx\n","  Downloading onnx-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13.5/13.5 MB 86.0 MB/s eta 0:00:00\n","Collecting onnx2tf\n","  Downloading onnx2tf-1.7.4-py3-none-any.whl (309 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 309.5/309.5 KB 32.7 MB/s eta 0:00:00\n","Collecting sng4onnx\n","  Downloading sng4onnx-1.0.1-py3-none-any.whl (5.8 kB)\n","Collecting onnxsim\n","  Downloading onnxsim-0.4.17-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2.1/2.1 MB 84.2 MB/s eta 0:00:00\n","Collecting onnx_graphsurgeon\n","  Downloading https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.26-py2.py3-none-any.whl (41 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 41.0/41.0 KB 5.1 MB/s eta 0:00:00\n","Collecting tflite_support\n","  Downloading tflite_support-0.4.3-cp38-cp38-manylinux2014_x86_64.whl (60.8 MB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 60.8/60.8 MB 20.3 MB/s eta 0:00:00\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.14.0-cp38-cp38-manylinux_2_27_x86_64.whl (5.0 MB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.0/5.0 MB 108.4 MB/s eta 0:00:00\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx) (4.5.0)\n","Collecting protobuf<4,>=3.20.2\n","  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.0/1.0 MB 63.3 MB/s eta 0:00:00\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx) (1.22.4)\n","Collecting rich\n","  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 239.0/239.0 KB 27.5 MB/s eta 0:00:00\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tflite_support) (1.4.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tflite_support) (23.1.21)\n","Collecting pybind11>=2.6.0\n","  Downloading pybind11-2.10.3-py3-none-any.whl (222 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 222.4/222.4 KB 24.5 MB/s eta 0:00:00\n","Collecting sounddevice>=0.4.4\n","  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (1.7.1)\n","Collecting coloredlogs\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 46.0/46.0 KB 5.7 MB/s eta 0:00:00\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (23.0)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.8/dist-packages (from sounddevice>=0.4.4->tflite_support) (1.15.1)\n","Collecting humanfriendly>=9.1\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 86.8/86.8 KB 11.8 MB/s eta 0:00:00\n","Collecting pygments<3.0.0,>=2.14.0\n","  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.1/1.1 MB 74.4 MB/s eta 0:00:00\n","Collecting markdown-it-py<3.0.0,>=2.1.0\n","  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 84.5/84.5 KB 11.4 MB/s eta 0:00:00\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime) (1.2.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite_support) (2.21)\n","Collecting mdurl~=0.1\n","  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Installing collected packages: sng4onnx, pygments, pybind11, protobuf, onnx2tf, mdurl, humanfriendly, sounddevice, onnx, markdown-it-py, coloredlogs, tflite_support, rich, onnxruntime, onnx_graphsurgeon, onnxsim\n","  Attempting uninstall: pygments\n","    Found existing installation: Pygments 2.6.1\n","    Uninstalling Pygments-2.6.1:\n","      Successfully uninstalled Pygments-2.6.1\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.19.6\n","    Uninstalling protobuf-3.19.6:\n","      Successfully uninstalled protobuf-3.19.6\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 markdown-it-py-2.2.0 mdurl-0.1.2 onnx-1.13.1 onnx2tf-1.7.4 onnx_graphsurgeon-0.3.26 onnxruntime-1.14.0 onnxsim-0.4.17 protobuf-3.20.3 pybind11-2.10.3 pygments-2.14.0 rich-13.3.1 sng4onnx-1.0.1 sounddevice-0.4.6 tflite_support-0.4.3\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m 7 packages updated per ('onnx', 'onnx2tf', 'sng4onnx', 'onnxsim', 'onnx_graphsurgeon', 'tflite_support', 'onnxruntime')\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.11.0...\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.1...\n","[Errno 2] No such file or directory: '/usr/local/lib/python3.8/dist-packages/protobuf-3.19.6.dist-info/METADATA'\n","\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.17...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.3s, saved as yolov8n.onnx (12.2 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m running onnx2tf -i yolov8n.onnx -o yolov8n_saved_model --non_verbose \n","WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n","2023-02-23 11:27:48.425322: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 54.7s, saved as yolov8n_saved_model (30.6 MB)\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ‚úÖ 0.0s, saved as yolov8n_saved_model/yolov8n_float32.tflite (12.2 MB)\n","\n","Export complete (55.1s)\n","Results saved to \u001b[1m/content\u001b[0m\n","Predict:         yolo predict task=detect model=yolov8n_saved_model/yolov8n_float32.tflite imgsz=640 \n","Validate:        yolo val task=detect model=yolov8n_saved_model/yolov8n_float32.tflite imgsz=640 data=coco.yaml \n","Visualize:       https://netron.app\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/tensorflow/examples.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P3HOghu5BqH4","executionInfo":{"status":"ok","timestamp":1677153486313,"user_tz":-60,"elapsed":11391,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"}},"outputId":"5f8cf48b-7158-4040-b2c8-592df6b92228"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'examples'...\n","remote: Enumerating objects: 22971, done.\u001b[K\n","remote: Counting objects: 100% (157/157), done.\u001b[K\n","remote: Compressing objects: 100% (120/120), done.\u001b[K\n","remote: Total 22971 (delta 46), reused 115 (delta 29), pack-reused 22814\u001b[K\n","Receiving objects: 100% (22971/22971), 42.11 MiB | 14.54 MiB/s, done.\n","Resolving deltas: 100% (12581/12581), done.\n","Updating files: 100% (2762/2762), done.\n"]}]},{"cell_type":"code","source":["!cd examples\n","!git sparse-checkout init --cone\n","!git sparse-checkout set lite/examples/object_detection/android"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9kOjECuIxXJ","executionInfo":{"status":"ok","timestamp":1677153517648,"user_tz":-60,"elapsed":2930,"user":{"displayName":"Gr√©goire Gratzmuller","userId":"10132416329281707762"}},"outputId":"f19a674c-666d-408e-db95-345f5b8259c0"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: not a git repository (or any of the parent directories): .git\n","fatal: not a git repository (or any of the parent directories): .git\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"fjsEGJ2oI6yB"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"766e5873d5f94600b4bcb71cfcec6efd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_120e844885494438a4b1afb1e5ffe5b5","IPY_MODEL_ae779d603a49440ebcf42dcf009aa5ef","IPY_MODEL_101ec31d0ebd4b8181e36ef55a96a826"],"layout":"IPY_MODEL_735b1752d46e42b8a61fac353e1863a0"}},"120e844885494438a4b1afb1e5ffe5b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a2e334d1a794a83b8440934f7d725ee","placeholder":"‚Äã","style":"IPY_MODEL_fe3b7a591b2f447fa3ce50730649a0f8","value":"100%"}},"ae779d603a49440ebcf42dcf009aa5ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fbc86026adb4af5a3752a6eeb2f085c","max":6534387,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e405c0be9354a299cde826f09593957","value":6534387}},"101ec31d0ebd4b8181e36ef55a96a826":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26837f892a524cc3b0643cd24e04c612","placeholder":"‚Äã","style":"IPY_MODEL_15add07839204a8fa90e6904fdff1c70","value":" 6.23M/6.23M [00:00&lt;00:00, 104MB/s]"}},"735b1752d46e42b8a61fac353e1863a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a2e334d1a794a83b8440934f7d725ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe3b7a591b2f447fa3ce50730649a0f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fbc86026adb4af5a3752a6eeb2f085c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e405c0be9354a299cde826f09593957":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26837f892a524cc3b0643cd24e04c612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15add07839204a8fa90e6904fdff1c70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f56087b4173f490995dbfc3e19daa9da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71e5bbbd56ca4ea2ab75923baba23d1b","IPY_MODEL_620d9275539440d68c50e8e399e8b000","IPY_MODEL_81c9cd9c06bd4227bac33ab1ff7e7e28"],"layout":"IPY_MODEL_c37569cbcc3f4a3ea9a71cd1acc67816"}},"71e5bbbd56ca4ea2ab75923baba23d1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19df18605ea4612b62f63e3363ddb3d","placeholder":"‚Äã","style":"IPY_MODEL_f31ca0841ade4b60a5b0f081decf6c22","value":"100%"}},"620d9275539440d68c50e8e399e8b000":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4171f0c132a44e44a2f8528d29887099","max":773236,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f7b1d924d8444babb5a1dd96f5dd6d1","value":773236}},"81c9cd9c06bd4227bac33ab1ff7e7e28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8287ccfe3d54ff7a5dc2ef9bfa70f9b","placeholder":"‚Äã","style":"IPY_MODEL_19aff64873ca4469a8c3bd734ef10e0b","value":" 755k/755k [00:00&lt;00:00, 28.9MB/s]"}},"c37569cbcc3f4a3ea9a71cd1acc67816":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d19df18605ea4612b62f63e3363ddb3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f31ca0841ade4b60a5b0f081decf6c22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4171f0c132a44e44a2f8528d29887099":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f7b1d924d8444babb5a1dd96f5dd6d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8287ccfe3d54ff7a5dc2ef9bfa70f9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19aff64873ca4469a8c3bd734ef10e0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}